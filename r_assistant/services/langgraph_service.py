"""
åŸºäºLangGraphçš„æ™ºèƒ½æœåŠ¡æ¥å£
æ›¿æ¢åŸæœ‰çš„ç®€å•AIæœåŠ¡ï¼Œæä¾›æ›´å¼ºå¤§çš„å·¥ä½œæµåŠŸèƒ½
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime

from django.conf import settings
from .langgraph_workflow import workflow_engine
from .workflow_state import Message, CodeSolution
from .ai_service import AIServiceError

logger = logging.getLogger(__name__)


class LangGraphService:
    """åŸºäºLangGraphçš„æ™ºèƒ½æœåŠ¡"""
    
    def __init__(self):
        self.workflow_engine = workflow_engine
        try:
            self.api_key_available = bool(getattr(settings, 'DEEPSEEK_API_KEY', ''))
        except Exception:
            import os
            self.api_key_available = bool(os.environ.get('DEEPSEEK_API_KEY', ''))
        
    def _check_api_availability(self):
        """æ£€æŸ¥APIæ˜¯å¦å¯ç”¨"""
        api_key = getattr(settings, 'DEEPSEEK_API_KEY', '')
        if not api_key or api_key.startswith('sk-è¯·æ›¿æ¢') or api_key == 'sk-placeholder-key-change-this':
            logger.warning("DEEPSEEK_API_KEYæœªæ­£ç¡®é…ç½®ï¼Œä½¿ç”¨æ¼”ç¤ºæ¨¡å¼")
            return False
        return True
        
    def _run_async(self, coro):
        """åœ¨åŒæ­¥ç¯å¢ƒä¸­è¿è¡Œå¼‚æ­¥ä»£ç """
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        return loop.run_until_complete(coro)
    
    def _convert_history_to_messages(self, conversation_history: List[Dict[str, str]]) -> List[Message]:
        """è½¬æ¢å¯¹è¯å†å²æ ¼å¼"""
        messages = []
        for item in conversation_history:
            message = Message(
                role=item.get("role", "user"),
                content=item.get("content", ""),
                timestamp=datetime.now()
            )
            messages.append(message)
        return messages
    
    def _format_code_solutions(self, solutions: List[CodeSolution]) -> List[Dict[str, Any]]:
        """æ ¼å¼åŒ–ä»£ç è§£å†³æ–¹æ¡ˆ"""
        formatted_solutions = []
        for solution in solutions:
            formatted_solutions.append({
                "title": solution.title,
                "code": solution.code,
                "explanation": solution.explanation,
                "difficulty": solution.difficulty,
                "packages": solution.packages,
                "filename": solution.filename
            })
        return formatted_solutions
    
    def explain_code(self, code: str, session_id: str = None, mode: str = 'full') -> Dict[str, Any]:
        """ä»£ç è§£é‡ŠæœåŠ¡ - ä½¿ç”¨LangGraphå·¥ä½œæµ
        
        Args:
            code: è¦è§£é‡Šçš„ä»£ç 
            session_id: ä¼šè¯ID
            mode: åˆ†ææ¨¡å¼ ('full', 'selected')
        """
        try:
            session_id = session_id or f"session_{datetime.now().timestamp()}"
            
            # æ£€æŸ¥APIå¯ç”¨æ€§
            if not self._check_api_availability():
                return self._create_demo_response("explain", code, mode)
            
            # æ‰§è¡Œå·¥ä½œæµ
            result = self._run_async(
                self.workflow_engine.execute_workflow(
                    request_type="explain",
                    user_input=code,
                    session_id=session_id
                )
            )
            
            # æ ¼å¼åŒ–è¿”å›ç»“æœ
            response = {
                "content": result.get("explanation_result") or result.get("ai_response", ""),
                "processing_time": result.get("processing_time", 0),
                "usage": {"total_tokens": result.get("total_tokens", 0)},
                "success": result.get("status") == "success",
                "analysis_mode": mode,
                "metadata": {
                    "workflow_steps": result.get("processing_steps", []),
                    "code_analysis": result.get("code_analysis"),
                    "quality_score": result.get("quality_score"),
                    "warnings": result.get("warnings", []),
                    "errors": result.get("errors", [])
                }
            }
            
            if not response["success"]:
                raise AIServiceError(f"ä»£ç è§£é‡Šå¤±è´¥: {'; '.join(result.get('errors', []))}")
            
            logger.info(f"ä»£ç è§£é‡Šå®Œæˆï¼ˆæ¨¡å¼ï¼š{mode}ï¼‰ï¼Œä¼šè¯ID: {session_id}")
            return response
            
        except Exception as e:
            logger.error(f"ä»£ç è§£é‡ŠæœåŠ¡å¤±è´¥: {str(e)}")
            raise AIServiceError(f"ä»£ç è§£é‡Šå¤±è´¥: {str(e)}")
    
    def solve_problem(self, problem: str, session_id: str = None, uploaded_files: List[Dict[str, Any]] = None) -> Dict[str, Any]:
        """é—®é¢˜æ±‚è§£æœåŠ¡ - ä½¿ç”¨LangGraphå·¥ä½œæµï¼Œæ”¯æŒæ–‡ä»¶ä¸Šä¼ """
        try:
            session_id = session_id or f"session_{datetime.now().timestamp()}"
            
            # æ£€æŸ¥APIå¯ç”¨æ€§
            if not self._check_api_availability():
                return self._create_demo_response("solve", problem, uploaded_files)
            
            # å‡†å¤‡æ–‡ä»¶å†…å®¹æè¿°
            file_context = ""
            if uploaded_files:
                file_context = "\n\nç›¸å…³æ–‡ä»¶å†…å®¹ï¼š\n"
                for file_info in uploaded_files:
                    file_context += f"\n--- æ–‡ä»¶: {file_info['filename']} (ç±»å‹: {file_info['type']}, å¤§å°: {file_info['size']} å­—èŠ‚) ---\n"
                    if file_info['content'].startswith('[äºŒè¿›åˆ¶æ–‡ä»¶'):
                        file_context += file_info['content'] + "\n"
                    else:
                        # é™åˆ¶æ–‡ä»¶å†…å®¹é•¿åº¦ï¼Œé¿å…è¿‡é•¿
                        content = file_info['content']
                        if len(content) > 5000:
                            content = content[:5000] + "\n... (å†…å®¹è¢«æˆªæ–­ï¼Œæ–‡ä»¶è¿‡é•¿)"
                        file_context += content + "\n"
                file_context += "\nè¯·åŸºäºä»¥ä¸Šæ–‡ä»¶å†…å®¹æ¥è§£å†³é—®é¢˜ã€‚"
            
            # ç»„åˆé—®é¢˜æè¿°å’Œæ–‡ä»¶å†…å®¹
            enhanced_problem = problem + file_context
            
            # æ‰§è¡Œå·¥ä½œæµ
            result = self._run_async(
                self.workflow_engine.execute_workflow(
                    request_type="answer",
                    user_input=enhanced_problem,
                    session_id=session_id
                )
            )
            
            # æ ¼å¼åŒ–è§£å†³æ–¹æ¡ˆ
            solutions = self._format_code_solutions(result.get("code_solutions", []))
            
            # æ ¼å¼åŒ–è¿”å›ç»“æœ
            response = {
                "content": result.get("ai_response", ""),
                "solutions": solutions,
                "processing_time": result.get("processing_time", 0),
                "usage": {"total_tokens": result.get("total_tokens", 0)},
                "success": result.get("status") == "success",
                "metadata": {
                    "workflow_steps": result.get("processing_steps", []),
                    "problem_type": result.get("problem_type"),
                    "warnings": result.get("warnings", []),
                    "errors": result.get("errors", []),
                    "uploaded_files_count": len(uploaded_files) if uploaded_files else 0
                }
            }
            
            if not response["success"]:
                raise AIServiceError(f"é—®é¢˜æ±‚è§£å¤±è´¥: {'; '.join(result.get('errors', []))}")
            
            logger.info(f"é—®é¢˜æ±‚è§£å®Œæˆï¼Œä¼šè¯ID: {session_id}ï¼Œç”Ÿæˆ{len(solutions)}ä¸ªè§£å†³æ–¹æ¡ˆï¼ŒåŒ…å«{len(uploaded_files) if uploaded_files else 0}ä¸ªæ–‡ä»¶")
            return response
            
        except Exception as e:
            logger.error(f"é—®é¢˜æ±‚è§£æœåŠ¡å¤±è´¥: {str(e)}")
            raise AIServiceError(f"é—®é¢˜æ±‚è§£å¤±è´¥: {str(e)}")
    
    def chat(self, message: str, conversation_history: List[Dict[str, str]] = None, 
             session_id: str = None) -> Dict[str, Any]:
        """æ™ºèƒ½å¯¹è¯æœåŠ¡ - ä½¿ç”¨LangGraphå·¥ä½œæµ"""
        try:
            session_id = session_id or f"session_{datetime.now().timestamp()}"
            
            # æ£€æŸ¥APIå¯ç”¨æ€§
            if not self._check_api_availability():
                return self._create_demo_response("chat", message)
            
            # è½¬æ¢å¯¹è¯å†å²
            history_messages = self._convert_history_to_messages(conversation_history or [])
            
            # æ‰§è¡Œå·¥ä½œæµ
            result = self._run_async(
                self.workflow_engine.execute_workflow(
                    request_type="talk",
                    user_input=message,
                    session_id=session_id,
                    conversation_history=history_messages
                )
            )
            
            # æ ¼å¼åŒ–è¿”å›ç»“æœ
            response = {
                "content": result.get("ai_response", ""),
                "processing_time": result.get("processing_time", 0),
                "usage": {"total_tokens": result.get("total_tokens", 0)},
                "success": result.get("status") == "success",
                "metadata": {
                    "workflow_steps": result.get("processing_steps", []),
                    "conversation_length": len(result.get("conversation_history", [])),
                    "warnings": result.get("warnings", []),
                    "errors": result.get("errors", [])
                }
            }
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å†…å®¹è¿”å›
            if not response["content"] and response["success"]:
                logger.warning("AIå“åº”ä¸ºç©ºï¼Œä½†çŠ¶æ€ä¸ºæˆåŠŸ")
                response["content"] = "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•ç”Ÿæˆå›å¤ï¼Œè¯·ç¨åå†è¯•ã€‚"
            
            if not response["success"]:
                error_msg = '; '.join(result.get('errors', [])) or "æœªçŸ¥é”™è¯¯"
                raise AIServiceError(f"æ™ºèƒ½å¯¹è¯å¤±è´¥: {error_msg}")
            
            logger.info(f"æ™ºèƒ½å¯¹è¯å®Œæˆï¼Œä¼šè¯ID: {session_id}")
            return response
            
        except Exception as e:
            logger.error(f"æ™ºèƒ½å¯¹è¯æœåŠ¡å¤±è´¥: {str(e)}")
            raise AIServiceError(f"æ™ºèƒ½å¯¹è¯å¤±è´¥: {str(e)}")
    
    def analyze_code_quality(self, code: str, session_id: str = None) -> Dict[str, Any]:
        """ä»£ç è´¨é‡åˆ†ææœåŠ¡"""
        try:
            session_id = session_id or f"session_{datetime.now().timestamp()}"
            
            # æ£€æŸ¥APIå¯ç”¨æ€§
            if not self._check_api_availability():
                return self._create_demo_response("analyze", code)
            
            # æ‰§è¡Œä»£ç è§£é‡Šå·¥ä½œæµï¼ˆåŒ…å«åˆ†æï¼‰
            result = self._run_async(
                self.workflow_engine.execute_workflow(
                    request_type="explain",
                    user_input=code,
                    session_id=session_id
                )
            )
            
            # æå–åˆ†æç»“æœ
            analysis = result.get("code_analysis", {})
            
            response = {
                "content": analysis.get("analysis_result", ""),
                "quality_score": analysis.get("quality_score", 0),
                "suggestions": analysis.get("suggestions", []),
                "complexity": analysis.get("complexity", "unknown"),
                "maintainability": analysis.get("maintainability", "unknown"),
                "processing_time": result.get("processing_time", 0),
                "usage": {"total_tokens": result.get("total_tokens", 0)},
                "success": result.get("status") == "success"
            }
            
            logger.info(f"ä»£ç è´¨é‡åˆ†æå®Œæˆï¼Œä¼šè¯ID: {session_id}")
            return response
            
        except Exception as e:
            logger.error(f"ä»£ç è´¨é‡åˆ†æå¤±è´¥: {str(e)}")
            raise AIServiceError(f"ä»£ç è´¨é‡åˆ†æå¤±è´¥: {str(e)}")
    
    def generate_tests(self, code: str, session_id: str = None) -> Dict[str, Any]:
        """æµ‹è¯•ç”¨ä¾‹ç”ŸæˆæœåŠ¡"""
        # æš‚æ—¶ä½¿ç”¨ç®€åŒ–å®ç°ï¼Œå¯ä»¥åç»­æ‰©å±•ä¸ºå®Œæ•´çš„å·¥ä½œæµ
        try:
            test_code = f"""
# ä¸ºä»¥ä¸‹ä»£ç ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹
# åŸå§‹ä»£ç :
{code}

# æµ‹è¯•ç”¨ä¾‹
library(testthat)

test_that("åŸºæœ¬åŠŸèƒ½æµ‹è¯•", {{
  # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
  expect_true(TRUE)
}})

test_that("è¾¹ç•Œæ¡ä»¶æµ‹è¯•", {{
  # æµ‹è¯•è¾¹ç•Œæ¡ä»¶
  expect_true(TRUE)
}})

test_that("å¼‚å¸¸å¤„ç†æµ‹è¯•", {{
  # æµ‹è¯•å¼‚å¸¸å¤„ç†
  expect_true(TRUE)
}})
"""
            
            response = {
                "content": test_code,
                "processing_time": 0.1,
                "usage": {"total_tokens": 100},
                "success": True
            }
            
            logger.info(f"æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå®Œæˆï¼Œä¼šè¯ID: {session_id}")
            return response
            
        except Exception as e:
            logger.error(f"æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¤±è´¥: {str(e)}")
            raise AIServiceError(f"æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¤±è´¥: {str(e)}")
    
    def optimize_code(self, code: str, session_id: str = None) -> Dict[str, Any]:
        """ä»£ç ä¼˜åŒ–æœåŠ¡"""
        # æš‚æ—¶ä½¿ç”¨ç®€åŒ–å®ç°ï¼Œå¯ä»¥åç»­æ‰©å±•ä¸ºå®Œæ•´çš„å·¥ä½œæµ
        try:
            optimized_code = f"""
# ä¼˜åŒ–åçš„ä»£ç 
# åŸå§‹ä»£ç :
{code}

# ä¼˜åŒ–å»ºè®®:
# 1. æ·»åŠ é”™è¯¯å¤„ç†
# 2. ä¼˜åŒ–æ€§èƒ½
# 3. æé«˜å¯è¯»æ€§

# ä¼˜åŒ–åçš„ä»£ç :
{code}  # è¿™é‡Œåº”è¯¥æ˜¯å®é™…ä¼˜åŒ–åçš„ä»£ç 
"""
            
            response = {
                "content": optimized_code,
                "processing_time": 0.1,
                "usage": {"total_tokens": 100},
                "success": True
            }
            
            logger.info(f"ä»£ç ä¼˜åŒ–å®Œæˆï¼Œä¼šè¯ID: {session_id}")
            return response
            
        except Exception as e:
            logger.error(f"ä»£ç ä¼˜åŒ–å¤±è´¥: {str(e)}")
            raise AIServiceError(f"ä»£ç ä¼˜åŒ–å¤±è´¥: {str(e)}")
    
    def _create_demo_response(self, request_type: str, user_input: str, mode_or_files = 'full') -> Dict[str, Any]:
        """åˆ›å»ºæ¼”ç¤ºå“åº”ï¼ˆå½“APIå¯†é’¥ä¸å¯ç”¨æ—¶ï¼‰"""
        # å¤„ç†å‚æ•°å…¼å®¹æ€§
        if isinstance(mode_or_files, list):
            uploaded_files = mode_or_files
            mode = 'full'
            file_info = f"\n\nğŸ“ **åŒ…å«{len(uploaded_files)}ä¸ªä¸Šä¼ æ–‡ä»¶ï¼š**\n"
            for file in uploaded_files:
                file_info += f"- {file['filename']} ({file['type']}, {file['size']} å­—èŠ‚)\n"
        else:
            mode = mode_or_files
            uploaded_files = None
            file_info = ""
        
        demo_responses = {
            "chat": f"ğŸ¤– **Rè¯­è¨€æ™ºèƒ½åŠ©æ‰‹æ¼”ç¤ºæ¨¡å¼**\n\nä½ å¥½ï¼æˆ‘æ˜¯Rè¯­è¨€æ™ºèƒ½åŠ©æ‰‹ã€‚\n\n**ä½ è¯´ï¼š** {user_input}\n\n---\n\nâš ï¸ **å½“å‰å¤„äºæ¼”ç¤ºæ¨¡å¼**\n\nè¦å¯ç”¨å®Œæ•´çš„AIåŠŸèƒ½ï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤é…ç½®APIå¯†é’¥ï¼š\n\n1. è®¿é—® https://platform.deepseek.com æ³¨å†Œè´¦å·\n2. è·å–æ‚¨çš„API Key\n3. åœ¨é¡¹ç›®æ ¹ç›®å½•çš„ `.env` æ–‡ä»¶ä¸­è®¾ç½®ï¼š\n   ```\n   DEEPSEEK_API_KEY=ä½ çš„APIå¯†é’¥\n   ```\n4. é‡å¯æœåŠ¡å™¨\n\n**é…ç½®å®Œæˆåï¼Œæˆ‘å¯ä»¥å¸®åŠ©ä½ ï¼š**\n- ğŸ“ è§£é‡ŠRä»£ç \n- ğŸ”§ è§£å†³ç¼–ç¨‹é—®é¢˜\n- ğŸ“š æä¾›å­¦ä¹ å»ºè®®\n- ğŸ“Š æ•°æ®åˆ†ææŒ‡å¯¼",
            
            "explain": f"ğŸ“ **ä»£ç è§£é‡ŠåŠŸèƒ½æ¼”ç¤º{' - é€‰ä¸­ä»£ç åˆ†æ' if mode == 'selected' else ''}**\n\n**ä½ æäº¤çš„ä»£ç ï¼š**\n```r\n{user_input}\n```\n\n---\n\nğŸ¯ **æ¼”ç¤ºè§£é‡Šï¼š**\n\nè¿™æ˜¯ä¸€ä¸ªæ¼”ç¤ºå“åº”ã€‚é…ç½®APIå¯†é’¥åï¼Œæˆ‘å°†ä¸ºä½ æä¾›è¯¦ç»†çš„ä»£ç åˆ†æï¼ŒåŒ…æ‹¬ï¼š\n\n- ğŸ“– é€è¡Œä»£ç è§£é‡Š\n- âš™ï¸ å‡½æ•°åŠŸèƒ½è¯´æ˜  \n- âœ¨ æœ€ä½³å®è·µå»ºè®®\n- ğŸš€ æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆ\n\n{f'**å½“å‰é€‰ä¸­ä»£ç åˆ†ææ¨¡å¼** - æˆ‘ä¼šé‡ç‚¹å…³æ³¨ä½ é€‰ä¸­çš„ä»£ç ç‰‡æ®µå¹¶ç»“åˆå®Œæ•´ä¸Šä¸‹æ–‡è¿›è¡Œåˆ†æã€‚' if mode == 'selected' else ''}\n\n---\n\nâš ï¸ **è¦å¯ç”¨å®Œæ•´åŠŸèƒ½ï¼Œè¯·é…ç½®DeepSeek APIå¯†é’¥ï¼š**\n\n1. è®¿é—® https://platform.deepseek.com\n2. åœ¨ `.env` æ–‡ä»¶ä¸­è®¾ç½® `DEEPSEEK_API_KEY`\n3. é‡å¯æœåŠ¡å™¨",
            
            "solve": f"ğŸ”§ **é—®é¢˜è§£å†³åŠŸèƒ½æ¼”ç¤º**\n\n**ä½ çš„é—®é¢˜ï¼š** {user_input}{file_info}\n\n---\n\nğŸ¯ **æ¼”ç¤ºè§£å†³æ–¹æ¡ˆï¼š**\n\nè¿™æ˜¯ä¸€ä¸ªæ¼”ç¤ºå“åº”ã€‚é…ç½®APIå¯†é’¥åï¼Œæˆ‘å°†æä¾›ï¼š\n\n- ğŸ”„ å¤šç§è§£å†³æ–¹æ¡ˆ\n- ğŸ’» è¯¦ç»†ä»£ç å®ç°\n- ğŸ“‹ æœ€ä½³å®è·µæŒ‡å¯¼\n- ğŸ“¦ ç›¸å…³åŒ…æ¨è\n{f'- ğŸ“ åŸºäºä¸Šä¼ æ–‡ä»¶çš„ä¸ªæ€§åŒ–è§£å†³æ–¹æ¡ˆ' if uploaded_files else ''}\n\n---\n\nâš ï¸ **é…ç½®APIå¯†é’¥ä»¥è·å¾—å®Œæ•´åŠŸèƒ½**",
            
            "analyze": f"ğŸ“Š **ä»£ç åˆ†æåŠŸèƒ½æ¼”ç¤º**\n\n**ä½ æäº¤çš„ä»£ç ï¼š**\n```r\n{user_input}\n```\n\n---\n\nğŸ¯ **æ¼”ç¤ºåˆ†æï¼š**\n\né…ç½®APIå¯†é’¥åï¼Œæˆ‘å°†æä¾›ï¼š\n\n- ğŸ“ˆ ä»£ç è´¨é‡è¯„åˆ†\n- âš¡ æ€§èƒ½åˆ†æå»ºè®®\n- ğŸ“ ä»£ç è§„èŒƒæ£€æŸ¥\n- ğŸ”§ ä¼˜åŒ–å»ºè®®\n\n---\n\nâš ï¸ **é…ç½®APIå¯†é’¥ä»¥è·å¾—å®Œæ•´åŠŸèƒ½**"
        }
        
        response = {
            "content": demo_responses.get(request_type, f"æ¼”ç¤ºå“åº”ï¼š{user_input}"),
            "processing_time": 0.1,
            "usage": {"total_tokens": 0},
            "success": True,
            "analysis_mode": mode,
            "metadata": {
                "demo_mode": True,
                "api_key_required": True,
                "message": "è¯·é…ç½®DEEPSEEK_API_KEYä»¥å¯ç”¨å®Œæ•´åŠŸèƒ½",
                "uploaded_files_count": len(uploaded_files) if uploaded_files else 0
            }
        }
        
        # ä¸ºæ±‚è§£é—®é¢˜æ·»åŠ æ¼”ç¤ºè§£å†³æ–¹æ¡ˆ
        if request_type == "solve":
            response["solutions"] = [
                {
                    "title": "æ¼”ç¤ºè§£å†³æ–¹æ¡ˆ 1",
                    "code": "# è¿™æ˜¯ä¸€ä¸ªæ¼”ç¤ºä»£ç \n# é…ç½®APIå¯†é’¥åå°†æä¾›çœŸå®è§£å†³æ–¹æ¡ˆ\nprint('Hello, R World!')",
                    "explanation": "è¿™æ˜¯æ¼”ç¤ºä»£ç è¯´æ˜ã€‚é…ç½®APIå¯†é’¥åå°†æä¾›è¯¦ç»†çš„é—®é¢˜åˆ†æå’Œå¤šç§è§£å†³æ–¹æ¡ˆã€‚",
                    "filename": "demo_solution.R"
                }
            ]
        
        return response


# åˆ›å»ºæœåŠ¡å·¥å‚
class LangGraphServiceFactory:
    """LangGraphæœåŠ¡å·¥å‚"""
    
    @staticmethod
    def get_service(service_type: str = 'langgraph') -> LangGraphService:
        """è·å–LangGraphæœåŠ¡å®ä¾‹"""
        if service_type == 'langgraph':
            return LangGraphService()
        else:
            raise AIServiceError(f"Unsupported service type: {service_type}")


# å…¨å±€æœåŠ¡å®ä¾‹
langgraph_service = LangGraphServiceFactory.get_service()